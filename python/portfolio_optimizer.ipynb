{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b595162",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the total investment amount: $4500000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  51 of 51 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ticker → Company mapping:\n",
      "ACU.AX = Acumentis Group Limited\n",
      "AGL.AX = AGL Energy Limited\n",
      "AHE.AX = Adheris Health Limited\n",
      "AIQ.AX = Alternative Investment Trust\n",
      "AMS.AX = Atomos Limited\n",
      "ANZ.AX = ANZ Group Holdings Limited\n",
      "APW.AX = Aims Property Securities Fund\n",
      "AQZ.AX = Alliance Aviation Services Limited\n",
      "AVD.AX = AVADA Group Limited\n",
      "BFL.AX = BSP Financial Group Limited\n",
      "BHP.AX = BHP Group Limited\n",
      "BNL.AX = Blue Star Helium Limited\n",
      "BPH.AX = BPH Energy Limited\n",
      "CAN.AX = Cann Group Limited\n",
      "CCG.AX = Comms Group Limited\n",
      "CLG.AX = Close the Loop Ltd\n",
      "CLZ.AX = Classic Minerals Limited\n",
      "COL.AX = Coles Group Limited\n",
      "DAI.AX = Decidr AI Industries Ltd\n",
      "DGT.AX = DIGICO INF STAPLED [DGT]\n",
      "DTI.AX = DTI Group Limited\n",
      "EDV.AX = Endeavour Group Limited\n",
      "ENN.AX = Elanor Investors Group\n",
      "EVN.AX = Evolution Mining Limited\n",
      "EWC.AX = Energy World Corporation Ltd\n",
      "FCG.AX = Freedom Care Group Holdings Limited\n",
      "GTN.AX = GTN Limited\n",
      "GYG.AX = Guzman y Gomez (Holdings) Ltd\n",
      "ILA.AX = Island Pharmaceuticals Limited\n",
      "INV.AX = InvestSMART Group Limited\n",
      "KNM.AX = KNeoMedia Limited\n",
      "KSL.AX = Kina Securities Limited\n",
      "LSX.AX = Lion Selection Group Limited\n",
      "MCP.AX = McPherson's Limited\n",
      "MFD.AX = Mayfield Childcare Limited\n",
      "MSI.AX = Multistack International Limited\n",
      "MTS.AX = Metcash Limited\n",
      "NOU.AX = Noumi Limited\n",
      "NTD.AX = NTAW Holdings Limited\n",
      "PTL.AX = Prestal Holdings Limited\n",
      "QAN.AX = Qantas Airways Limited\n",
      "QBE.AX = QBE Insurance Group Limited\n",
      "RPM.AX = RPM Automotive Group Limited\n",
      "SFX.AX = Sheffield Resources Limited\n",
      "SPK.AX = Spark New Zealand Limited\n",
      "STP.AX = Step One Clothing Limited\n",
      "TIA.AX = Tian An Australia Limited\n",
      "VEN.AX = Vintage Energy Limited\n",
      "VGN.AX = Virgin Australia Holdings Ltd\n",
      "VMT.AX = Vmoto Limited\n",
      "X2M.AX = X2M Connect Limited\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CSV saved: Portfolio_Optimisation_Results.csv\n",
      "\n",
      "Power BI exports saved to: C:\\Users\\jed1n\\Documents\\portfolio_optimizer\\powerbi_exports\n",
      "Files:\n",
      "- pb_allocations_long.csv\n",
      "- pb_portfolio_timeseries.csv (includes Benchmark)\n",
      "- pb_metrics.csv (includes Benchmark)\n",
      "- pb_frontier_points.csv\n",
      "- pb_ticker_map.csv\n",
      "\n",
      "Saved: efficient_frontier.png\n",
      "Saved all pie charts.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "from datetime import date\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "\n",
    "# ============================================================\n",
    "# SETTINGS\n",
    "# ============================================================\n",
    "START_DATE = \"2018-01-01\"\n",
    "END_DATE = date.today().strftime(\"%Y-%m-%d\")  # excludes today (yfinance end= is exclusive)\n",
    "\n",
    "TRADING_DAYS = 252\n",
    "RISK_FREE_RATE = 0.04\n",
    "\n",
    "NUM_PORTFOLIOS = 5000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "TICKERS_CSV = \"tickers.csv\"\n",
    "\n",
    "# Benchmark options:\n",
    "# - Australia index: \"^AXJO\" (ASX 200 index)\n",
    "# - Australia ETF: \"A200.AX\"\n",
    "# - US index: \"^GSPC\" (S&P 500)\n",
    "# - US ETF: \"SPY\"\n",
    "BENCHMARK_TICKER = \"^AXJO\"\n",
    "BENCHMARK_NAME = \"Benchmark\"\n",
    "\n",
    "# Power BI export folder\n",
    "PBI_OUT_DIR = Path(\"powerbi_exports\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# FUNCTION: Get company name from Yahoo Finance\n",
    "# ============================================================\n",
    "def get_company_name(ticker: str) -> str:\n",
    "    try:\n",
    "        info = yf.Ticker(ticker).info\n",
    "        return info.get(\"longName\") or info.get(\"shortName\") or ticker\n",
    "    except Exception:\n",
    "        return ticker\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# PORTFOLIO METRICS (EXPECTED, FROM MEAN/COV)\n",
    "# ============================================================\n",
    "def portfolio_performance(weights, mean_returns, cov_matrix, risk_free_rate=RISK_FREE_RATE):\n",
    "    \"\"\"\n",
    "    Expected annualised return, volatility, and Sharpe based on mean_returns and cov_matrix.\n",
    "    \"\"\"\n",
    "    weights = np.array(weights, dtype=float)\n",
    "\n",
    "    mu = np.array(mean_returns, dtype=float)\n",
    "    cov = np.array(cov_matrix, dtype=float)\n",
    "\n",
    "    ret = float(np.dot(weights, mu))\n",
    "    vol = float(np.sqrt(np.dot(weights.T, np.dot(cov, weights))))\n",
    "    sharpe = (ret - risk_free_rate) / vol if vol != 0 else 0.0\n",
    "    return ret, vol, sharpe\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# RANDOM PORTFOLIOS (FOR FRONTIER CLOUD)\n",
    "# ============================================================\n",
    "def generate_random_portfolios(num_portfolios, mean_returns, cov_matrix,\n",
    "                               risk_free_rate=RISK_FREE_RATE, seed=RANDOM_SEED):\n",
    "    np.random.seed(seed)\n",
    "    n_assets = len(mean_returns)\n",
    "\n",
    "    results = {\"returns\": [], \"volatility\": [], \"sharpe\": [], \"weights\": []}\n",
    "\n",
    "    for _ in range(num_portfolios):\n",
    "        weights = np.random.random(n_assets)\n",
    "        weights /= weights.sum()\n",
    "\n",
    "        ret, vol, sharpe = portfolio_performance(weights, mean_returns, cov_matrix, risk_free_rate)\n",
    "\n",
    "        results[\"returns\"].append(ret)\n",
    "        results[\"volatility\"].append(vol)\n",
    "        results[\"sharpe\"].append(sharpe)\n",
    "        results[\"weights\"].append(weights)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BACKTEST + REALISED METRICS (FROM DAILY RETURNS)\n",
    "# ============================================================\n",
    "def backtest_portfolio(returns_df: pd.DataFrame, weights: np.ndarray) -> pd.Series:\n",
    "    \"\"\"\n",
    "    returns_df: daily returns DataFrame with columns aligned to tickers\n",
    "    weights: numpy array aligned to tickers\n",
    "    returns: daily portfolio returns Series\n",
    "    \"\"\"\n",
    "    w = np.array(weights, dtype=float)\n",
    "    return (returns_df * w).sum(axis=1)\n",
    "\n",
    "\n",
    "def perf_metrics_from_daily_returns(daily_ret: pd.Series, risk_free_rate=RISK_FREE_RATE) -> dict:\n",
    "    \"\"\"\n",
    "    Realised metrics from daily returns.\n",
    "    \"\"\"\n",
    "    daily_ret = daily_ret.dropna()\n",
    "    n = len(daily_ret)\n",
    "    if n == 0:\n",
    "        return {\"CAGR\": np.nan, \"Vol\": np.nan, \"Sharpe\": np.nan, \"MaxDrawdown\": np.nan}\n",
    "\n",
    "    equity = (1 + daily_ret).cumprod()\n",
    "    total_return = equity.iloc[-1] - 1\n",
    "\n",
    "    cagr = (1 + total_return) ** (TRADING_DAYS / n) - 1\n",
    "    vol = daily_ret.std(ddof=0) * np.sqrt(TRADING_DAYS)\n",
    "    ann_ret = daily_ret.mean() * TRADING_DAYS\n",
    "    sharpe = (ann_ret - risk_free_rate) / vol if vol != 0 else np.nan\n",
    "\n",
    "    running_max = equity.cummax()\n",
    "    drawdown = equity / running_max - 1\n",
    "    max_dd = float(drawdown.min())\n",
    "\n",
    "    return {\"CAGR\": float(cagr), \"Vol\": float(vol), \"Sharpe\": float(sharpe), \"MaxDrawdown\": max_dd}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# MAIN\n",
    "# ============================================================\n",
    "def main():\n",
    "    # -------------------------\n",
    "    # USER INPUT\n",
    "    # -------------------------\n",
    "    amount_of_money = float(input(\"What is the total investment amount: $\"))\n",
    "\n",
    "    tickers_df = pd.read_csv(TICKERS_CSV)\n",
    "    tickers_df[\"ticker\"] = tickers_df[\"ticker\"].astype(str).str.strip()\n",
    "    tickers = tickers_df[\"ticker\"].dropna().tolist()\n",
    "\n",
    "    if len(tickers) == 0:\n",
    "        raise ValueError(\"No tickers found in tickers.csv under column 'ticker'.\")\n",
    "\n",
    "    # -------------------------\n",
    "    # DOWNLOAD PRICE DATA (PORTFOLIO ASSETS)\n",
    "    # -------------------------\n",
    "    data = yf.download(\n",
    "        tickers,\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "        auto_adjust=True,\n",
    "        progress=True\n",
    "    )[\"Close\"]\n",
    "\n",
    "    data = data.ffill().bfill()\n",
    "\n",
    "    # Only keep tickers that downloaded successfully\n",
    "    final_tickers = list(data.columns)\n",
    "    if len(final_tickers) == 0:\n",
    "        raise ValueError(\"No price data downloaded. Check tickers or date range.\")\n",
    "\n",
    "    # Company names aligned to final tickers\n",
    "    company_names = [get_company_name(t) for t in final_tickers]\n",
    "\n",
    "    print(\"\\nTicker → Company mapping:\")\n",
    "    for t, n in zip(final_tickers, company_names):\n",
    "        print(f\"{t} = {n}\")\n",
    "\n",
    "    latest_prices = data.iloc[-1]  # aligned with final_tickers\n",
    "\n",
    "    # -------------------------\n",
    "    # DOWNLOAD BENCHMARK PRICE DATA\n",
    "    # -------------------------\n",
    "    bench_close = yf.download(\n",
    "        BENCHMARK_TICKER,\n",
    "        start=START_DATE,\n",
    "        end=END_DATE,\n",
    "        auto_adjust=True,\n",
    "        progress=True\n",
    "    )[\"Close\"]\n",
    "\n",
    "    # yfinance sometimes returns a 1-col DataFrame; ensure Series\n",
    "    if isinstance(bench_close, pd.DataFrame):\n",
    "        bench_close = bench_close.iloc[:, 0]\n",
    "\n",
    "    bench_close = bench_close.ffill().bfill()\n",
    "\n",
    "    # -------------------------\n",
    "    # RETURNS + COVARIANCE\n",
    "    # -------------------------\n",
    "    returns = data.pct_change().dropna()\n",
    "    bench_returns = bench_close.pct_change()\n",
    "\n",
    "    # Align benchmark returns to portfolio returns dates\n",
    "    bench_returns = bench_returns.reindex(returns.index).ffill().bfill().dropna()\n",
    "\n",
    "    # Ensure perfect index match\n",
    "    common_idx = returns.index.intersection(bench_returns.index)\n",
    "    returns = returns.loc[common_idx]\n",
    "    bench_returns = bench_returns.loc[common_idx]\n",
    "\n",
    "    mean_returns = returns.mean() * TRADING_DAYS\n",
    "    cov_matrix = returns.cov() * TRADING_DAYS\n",
    "\n",
    "    # -------------------------\n",
    "    # RANDOM PORTFOLIOS\n",
    "    # -------------------------\n",
    "    rp = generate_random_portfolios(NUM_PORTFOLIOS, mean_returns.values, cov_matrix.values)\n",
    "\n",
    "    returns_array = np.array(rp[\"returns\"])\n",
    "    vol_array = np.array(rp[\"volatility\"])\n",
    "    sharpe_array = np.array(rp[\"sharpe\"])\n",
    "    weights_array = np.array(rp[\"weights\"])\n",
    "\n",
    "    # -------------------------\n",
    "    # OPTIMAL PORTFOLIOS\n",
    "    # -------------------------\n",
    "    max_sharpe_idx = sharpe_array.argmax()\n",
    "    min_vol_idx = vol_array.argmin()\n",
    "\n",
    "    max_sharpe_w = weights_array[max_sharpe_idx]\n",
    "    min_vol_w = weights_array[min_vol_idx]\n",
    "\n",
    "    max_sharpe_ret, max_sharpe_vol, max_sharpe_ratio = portfolio_performance(\n",
    "        max_sharpe_w, mean_returns.values, cov_matrix.values, RISK_FREE_RATE\n",
    "    )\n",
    "    min_vol_ret, min_vol_vol, min_vol_ratio = portfolio_performance(\n",
    "        min_vol_w, mean_returns.values, cov_matrix.values, RISK_FREE_RATE\n",
    "    )\n",
    "\n",
    "    # MaxReturn portfolio (highest expected return among random portfolios)\n",
    "    max_return_idx = returns_array.argmax()\n",
    "    max_return_w = weights_array[max_return_idx]\n",
    "    max_return_ret, max_return_vol, max_return_sharpe = portfolio_performance(\n",
    "        max_return_w, mean_returns.values, cov_matrix.values, RISK_FREE_RATE\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # EQUAL WEIGHT PORTFOLIO\n",
    "    # -------------------------\n",
    "    equal_weights = np.ones(len(final_tickers)) / len(final_tickers)\n",
    "    ew_return, ew_vol, ew_sharpe = portfolio_performance(\n",
    "        equal_weights, mean_returns.values, cov_matrix.values, RISK_FREE_RATE\n",
    "    )\n",
    "\n",
    "    # -------------------------\n",
    "    # SHARES + DOLLAR ALLOCATIONS\n",
    "    # -------------------------\n",
    "    alloc_max_sharpe = max_sharpe_w * amount_of_money\n",
    "    alloc_min_vol = min_vol_w * amount_of_money\n",
    "    alloc_equal = equal_weights * amount_of_money\n",
    "    alloc_max_return = max_return_w * amount_of_money\n",
    "\n",
    "    shares_max = alloc_max_sharpe / latest_prices.values\n",
    "    shares_min = alloc_min_vol / latest_prices.values\n",
    "    shares_eq = alloc_equal / latest_prices.values\n",
    "    shares_ret = alloc_max_return / latest_prices.values\n",
    "\n",
    "    # -------------------------\n",
    "    # CREATE OUTPUT TABLE (BASE, NO TOTAL ROW)\n",
    "    # -------------------------\n",
    "    allocations_df_base = pd.DataFrame({\n",
    "        \"Ticker\": final_tickers,\n",
    "        \"Company\": company_names,\n",
    "        \"LatestPrice\": latest_prices.values,\n",
    "\n",
    "        \"MaxSharpeWeight\": max_sharpe_w,\n",
    "        \"MaxSharpe$\": alloc_max_sharpe,\n",
    "        \"MaxSharpeShares\": shares_max,\n",
    "\n",
    "        \"MinVolWeight\": min_vol_w,\n",
    "        \"MinVol$\": alloc_min_vol,\n",
    "        \"MinVolShares\": shares_min,\n",
    "\n",
    "        \"MaxReturnWeight\": max_return_w,\n",
    "        \"MaxReturn$\": alloc_max_return,\n",
    "        \"MaxReturnShares\": shares_ret,\n",
    "\n",
    "        \"EqualWeight\": equal_weights,\n",
    "        \"EqualWeight$\": alloc_equal,\n",
    "        \"EqualWeightShares\": shares_eq\n",
    "    })\n",
    "\n",
    "    # TOTAL ROW (for the human-friendly CSV only)\n",
    "    total_row = pd.DataFrame({\n",
    "        \"Ticker\": [\"TOTAL\"],\n",
    "        \"Company\": [\"\"],\n",
    "        \"LatestPrice\": [np.nan],\n",
    "\n",
    "        \"MaxSharpeWeight\": [max_sharpe_w.sum()],\n",
    "        \"MaxSharpe$\": [alloc_max_sharpe.sum()],\n",
    "        \"MaxSharpeShares\": [shares_max.sum()],\n",
    "\n",
    "        \"MinVolWeight\": [min_vol_w.sum()],\n",
    "        \"MinVol$\": [alloc_min_vol.sum()],\n",
    "        \"MinVolShares\": [shares_min.sum()],\n",
    "\n",
    "        \"MaxReturnWeight\": [max_return_w.sum()],\n",
    "        \"MaxReturn$\": [alloc_max_return.sum()],\n",
    "        \"MaxReturnShares\": [shares_ret.sum()],\n",
    "\n",
    "        \"EqualWeight\": [equal_weights.sum()],\n",
    "        \"EqualWeight$\": [alloc_equal.sum()],\n",
    "        \"EqualWeightShares\": [shares_eq.sum()]\n",
    "    })\n",
    "\n",
    "    allocations_df_output = pd.concat([allocations_df_base, total_row], ignore_index=True)\n",
    "\n",
    "    # -------------------------\n",
    "    # EXPORT HUMAN-FRIENDLY CSV\n",
    "    # -------------------------\n",
    "    allocations_df_output.to_csv(\"Portfolio_Optimisation_Results.csv\", index=False)\n",
    "    print(\"\\nCSV saved: Portfolio_Optimisation_Results.csv\")\n",
    "\n",
    "    # =========================================================\n",
    "    # POWER BI EXPORTS (TIDY TABLES)\n",
    "    # =========================================================\n",
    "    PBI_OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "    # 1) Allocations LONG (benchmark doesn't belong here)\n",
    "    alloc_long_parts = []\n",
    "\n",
    "    def add_strategy(strategy_name, w_col, usd_col, sh_col):\n",
    "        tmp = allocations_df_base[[\"Ticker\", \"Company\", \"LatestPrice\"]].copy()\n",
    "        tmp[\"Strategy\"] = strategy_name\n",
    "        tmp[\"IsBenchmark\"] = False\n",
    "        tmp[\"Weight\"] = allocations_df_base[w_col].astype(float).values\n",
    "        tmp[\"DollarAlloc\"] = allocations_df_base[usd_col].astype(float).values\n",
    "        tmp[\"Shares\"] = allocations_df_base[sh_col].astype(float).values\n",
    "        alloc_long_parts.append(tmp)\n",
    "\n",
    "    add_strategy(\"MaxSharpe\", \"MaxSharpeWeight\", \"MaxSharpe$\", \"MaxSharpeShares\")\n",
    "    add_strategy(\"MinVol\", \"MinVolWeight\", \"MinVol$\", \"MinVolShares\")\n",
    "    add_strategy(\"MaxReturn\", \"MaxReturnWeight\", \"MaxReturn$\", \"MaxReturnShares\")\n",
    "    add_strategy(\"Equal\", \"EqualWeight\", \"EqualWeight$\", \"EqualWeightShares\")\n",
    "\n",
    "    allocations_long = pd.concat(alloc_long_parts, ignore_index=True)\n",
    "    allocations_long.to_csv(PBI_OUT_DIR / \"pb_allocations_long.csv\", index=False)\n",
    "\n",
    "    # 2) Backtest equity curves (constant weights) + BENCHMARK\n",
    "    daily_ret_max = backtest_portfolio(returns, max_sharpe_w)\n",
    "    daily_ret_min = backtest_portfolio(returns, min_vol_w)\n",
    "    daily_ret_ret = backtest_portfolio(returns, max_return_w)\n",
    "    daily_ret_eq = backtest_portfolio(returns, equal_weights)\n",
    "\n",
    "    bt = pd.DataFrame({\n",
    "        \"Date\": returns.index,\n",
    "        \"MaxSharpe\": daily_ret_max.values,\n",
    "        \"MinVol\": daily_ret_min.values,\n",
    "        \"MaxReturn\": daily_ret_ret.values,\n",
    "        \"Equal\": daily_ret_eq.values,\n",
    "        BENCHMARK_NAME: bench_returns.values\n",
    "    })\n",
    "\n",
    "    bt_long = bt.melt(id_vars=\"Date\", var_name=\"Strategy\", value_name=\"DailyReturn\")\n",
    "    bt_long[\"IsBenchmark\"] = bt_long[\"Strategy\"].eq(BENCHMARK_NAME)\n",
    "    bt_long[\"EquityCurve\"] = bt_long.groupby(\"Strategy\")[\"DailyReturn\"].transform(lambda s: (1 + s).cumprod())\n",
    "    bt_long[\"EquityCurve_$\"] = bt_long[\"EquityCurve\"] * amount_of_money\n",
    "    bt_long.to_csv(PBI_OUT_DIR / \"pb_portfolio_timeseries.csv\", index=False)\n",
    "\n",
    "    # 3) Metrics table (realised) + BENCHMARK\n",
    "    m_max = perf_metrics_from_daily_returns(daily_ret_max, RISK_FREE_RATE)\n",
    "    m_min = perf_metrics_from_daily_returns(daily_ret_min, RISK_FREE_RATE)\n",
    "    m_ret = perf_metrics_from_daily_returns(daily_ret_ret, RISK_FREE_RATE)\n",
    "    m_eq = perf_metrics_from_daily_returns(daily_ret_eq, RISK_FREE_RATE)\n",
    "    m_bm = perf_metrics_from_daily_returns(bench_returns, RISK_FREE_RATE)\n",
    "\n",
    "    metrics_df = pd.DataFrame([\n",
    "        {\"Strategy\": \"MaxSharpe\", \"IsBenchmark\": False, **m_max},\n",
    "        {\"Strategy\": \"MinVol\", \"IsBenchmark\": False, **m_min},\n",
    "        {\"Strategy\": \"MaxReturn\", \"IsBenchmark\": False, **m_ret},\n",
    "        {\"Strategy\": \"Equal\", \"IsBenchmark\": False, **m_eq},\n",
    "        {\"Strategy\": BENCHMARK_NAME, \"IsBenchmark\": True, **m_bm},\n",
    "    ])\n",
    "    metrics_df.to_csv(PBI_OUT_DIR / \"pb_metrics.csv\", index=False)\n",
    "\n",
    "    # 4) Efficient frontier points (optional Power BI scatter)\n",
    "    frontier_points = pd.DataFrame({\n",
    "        \"PortfolioID\": np.arange(len(vol_array)),\n",
    "        \"Volatility\": vol_array,\n",
    "        \"ExpectedReturn\": returns_array,\n",
    "        \"Sharpe\": sharpe_array\n",
    "    })\n",
    "    frontier_points.to_csv(PBI_OUT_DIR / \"pb_frontier_points.csv\", index=False)\n",
    "\n",
    "    # 5) Ticker map (optional)\n",
    "    ticker_map = pd.DataFrame({\"Ticker\": final_tickers, \"Company\": company_names})\n",
    "    ticker_map.to_csv(PBI_OUT_DIR / \"pb_ticker_map.csv\", index=False)\n",
    "\n",
    "    print(f\"\\nPower BI exports saved to: {PBI_OUT_DIR.resolve()}\")\n",
    "    print(\"Files:\")\n",
    "    print(\"- pb_allocations_long.csv\")\n",
    "    print(\"- pb_portfolio_timeseries.csv (includes Benchmark)\")\n",
    "    print(\"- pb_metrics.csv (includes Benchmark)\")\n",
    "    print(\"- pb_frontier_points.csv\")\n",
    "    print(\"- pb_ticker_map.csv\")\n",
    "\n",
    "    # =========================================================\n",
    "    # PLOTS + SAVE\n",
    "    # =========================================================\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.scatter(vol_array, returns_array, c=sharpe_array, cmap=\"viridis\", s=10, alpha=0.6)\n",
    "    plt.colorbar(label=\"Sharpe Ratio\")\n",
    "\n",
    "    plt.scatter(max_sharpe_vol, max_sharpe_ret, s=250, marker=\"*\", color=\"red\", label=\"Max Sharpe\")\n",
    "    plt.scatter(min_vol_vol, min_vol_ret, s=250, marker=\"*\", color=\"blue\", label=\"Min Volatility\")\n",
    "    plt.scatter(max_return_vol, max_return_ret, s=250, marker=\"*\", color=\"green\", label=\"Max Return\")\n",
    "\n",
    "    plt.xlabel(\"Volatility\")\n",
    "    plt.ylabel(\"Expected Return\")\n",
    "    plt.title(\"Efficient Frontier\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(\"efficient_frontier.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"\\nSaved: efficient_frontier.png\")\n",
    "\n",
    "    # Pie charts\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(max_sharpe_w, labels=final_tickers, autopct=\"%1.1f%%\")\n",
    "    plt.title(\"Max Sharpe Portfolio\")\n",
    "    plt.savefig(\"max_sharpe_allocation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(min_vol_w, labels=final_tickers, autopct=\"%1.1f%%\")\n",
    "    plt.title(\"Minimum Volatility Portfolio\")\n",
    "    plt.savefig(\"min_vol_allocation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(max_return_w, labels=final_tickers, autopct=\"%1.1f%%\")\n",
    "    plt.title(\"Maximum Return Portfolio\")\n",
    "    plt.savefig(\"max_return_allocation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(equal_weights, labels=final_tickers, autopct=\"%1.1f%%\")\n",
    "    plt.title(\"Equal Weight Portfolio\")\n",
    "    plt.savefig(\"equal_weight_allocation.png\", dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "    print(\"Saved all pie charts.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74b66b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (finance)",
   "language": "python",
   "name": "finance"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
